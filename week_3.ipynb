{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split as tts\n",
    "from sklearn import preprocessing as pr\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "from sklearn import cross_validation\n",
    "from sklearn import ensemble\n",
    "\n",
    "\n",
    "%matplotlib inline \n",
    "%pylab inline\n",
    "\n",
    "def read_data():\n",
    "    churn_data = pd.read_csv('orange_small_churn_data.train')\n",
    "    with open('orange_small_churn_labels.train') as reader:\n",
    "        churn_data['label'] = np.array(map(int, reader.read().split()))\n",
    "    return churn_data\n",
    "\n",
    "\n",
    "def get_train_data():\n",
    "    np.random.seed(0)\n",
    "    data = read_data()\n",
    "    data_train, data_test = tts(data, test_size=0.25)\n",
    "    # отбрасываем тестовые данные\n",
    "    return data_train\n",
    "\n",
    "\n",
    "def judge_classifier(classifier, X, y, metrics=None):\n",
    "    # Метод для проверки классификатора на нужных метриках\n",
    "    if not metrics:\n",
    "        metrics = ['roc_auc', 'accuracy', 'recall', 'f1_weighted'] \n",
    "    # Объявим стратегию кросс-валидации\n",
    "    cv_strategy = cross_validation.StratifiedKFold(y, n_folds=5, random_state = 2)\n",
    "    print(classifier)\n",
    "    for metric in metrics:\n",
    "        # Считаем метрики\n",
    "        scores = cross_validation.cross_val_score(classifier, X, y, scoring=metric, cv = cv_strategy)\n",
    "        print(\"Scores for metric %s:\" % metric)\n",
    "        print(scores)\n",
    "        print(scores.mean())\n",
    "    print(\"=====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vgridnev/anaconda/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:17: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/vgridnev/anaconda/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/vgridnev/anaconda/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "def normalize(s, labels):\n",
    "    if sum(s.isnull()) == len(s):\n",
    "        return (np.nan, 0, 0)\n",
    "    mean = np.array(s.dropna()).mean()\n",
    "    std = np.array(s.dropna()).std()\n",
    "    s.fillna(mean, inplace=True)\n",
    "    s.apply(lambda x: (x - mean) / std)\n",
    "    a = s[labels < 0].mean()\n",
    "    b = s[labels > 0].mean()\n",
    "    return ((a - b), mean, std)\n",
    "\n",
    "def prepare_train_data(data, truncate=False):\n",
    "    bad_features = []\n",
    "    columns = list(data.columns)[:-1]\n",
    "    for (idx, column) in enumerate(columns[:190]):\n",
    "        value, mean, std = normalize(data[column].copy(), data.label)\n",
    "        # нормализуем данные\n",
    "        if np.isnan(value) or np.isnan(mean / std) or np.isinf(mean / std):\n",
    "            bad_features.append(column)\n",
    "        else:\n",
    "            data[column].fillna(mean, inplace=True)\n",
    "            data[column] = data[column].apply(lambda x: (x - mean) / std)\n",
    "    numerical_data = data[columns[:190]]\n",
    "    for feature in bad_features:\n",
    "        # удаляем \"плохие признаки\", являющиеся константными\n",
    "        numerical_data = numerical_data.drop(feature, axis=1)\n",
    "    categorial_features = [(\"Var%d\" % i) for i in range(191, 230)]\n",
    "    cat_bad_features = []\n",
    "    for feature in categorial_features:\n",
    "        if len(set(data[feature])) == 1:\n",
    "            # признак константный, удаляем\n",
    "            cat_bad_features.append(feature)\n",
    "    cat_data = data[categorial_features]\n",
    "    for cat in categorial_features:\n",
    "        cat_data[cat] = cat_data[cat].apply(lambda x: str(x))\n",
    "        value_counts = cat_data[cat].value_counts()\n",
    "        if truncate:\n",
    "            # Для того чтобы ускорить обучение ограничим данные\n",
    "            cat_data[cat] = cat_data[cat].apply(lambda x: x if value_counts[x] >= 50 else 'nan')\n",
    "    for cat in cat_bad_features:\n",
    "        # удаляем \"плохие признаки\", являющиеся константными\n",
    "        cat_data = cat_data.drop(cat, axis=1)\n",
    "    \n",
    "    encoder = DV(sparse = False)\n",
    "    encoded_data = encoder.fit_transform(cat_data.T.to_dict().values())\n",
    "    prepared_data = np.concatenate([numerical_data.as_matrix(), encoded_data], axis=1)\n",
    "    return prepared_data, data.label\n",
    "\n",
    "data = get_train_data()\n",
    "X, y = prepare_train_data(data, truncate=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=2, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Scores for metric roc_auc:\n",
      "[ 0.59604075  0.60908674  0.60102175  0.61145798  0.5879523 ]\n",
      "0.601111905006\n",
      "Scores for metric accuracy:\n",
      "[ 0.92384603  0.92416667  0.92366667  0.925       0.92315386]\n",
      "0.923966643594\n",
      "Scores for metric recall:\n",
      "[ 0.          0.00446429  0.00446429  0.          0.00669643]\n",
      "0.003125\n",
      "Scores for metric f1_weighted:\n",
      "[ 0.88855663  0.88950307  0.88924876  0.88928139  0.88928679]\n",
      "0.889175326778\n",
      "=====\n"
     ]
    }
   ],
   "source": [
    "judge_classifier(linear_model.LogisticRegression(random_state = 2), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=2, verbose=0, warm_start=False)\n",
      "Scores for metric roc_auc:\n",
      "[ 0.567743    0.5602176   0.6022124   0.56645188  0.57550964]\n",
      "0.574426905297\n",
      "Scores for metric accuracy:\n",
      "[ 0.9250125   0.92533333  0.925       0.92516667  0.9249875 ]\n",
      "0.925099999167\n",
      "Scores for metric recall:\n",
      "[ 0.00222717  0.          0.          0.          0.        ]\n",
      "0.000445434298441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vgridnev/anaconda/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for metric f1_weighted:\n",
      "[ 0.88946426  0.88944783  0.88928139  0.88936461  0.88926318]\n",
      "0.889364254479\n",
      "=====\n"
     ]
    }
   ],
   "source": [
    "judge_classifier(ensemble.RandomForestClassifier(random_state = 2), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=2, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "Scores for metric roc_auc:\n",
      "[ 0.7106045   0.70749179  0.72364387  0.71778268  0.71215571]\n",
      "0.714335709911\n",
      "Scores for metric accuracy:\n",
      "[ 0.9250125   0.92483333  0.9255      0.92533333  0.92432072]\n",
      "0.924999976941\n",
      "Scores for metric recall:\n",
      "[ 0.00445434  0.00669643  0.00892857  0.00669643  0.        ]\n",
      "0.00535515431117\n",
      "Scores for metric f1_weighted:\n",
      "[ 0.88978617  0.89015966  0.89081904  0.89041597  0.88893006]\n",
      "0.890022180676\n",
      "=====\n"
     ]
    }
   ],
   "source": [
    "judge_classifier(ensemble.GradientBoostingClassifier(random_state = 2), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
